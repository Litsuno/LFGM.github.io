{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5yiH5h8x3h"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# 使用Gemini进行笔记整理\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 准备工作"
      ],
      "metadata": {
        "id": "-AXWO9R85Jae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IbKkL5ksQYq1",
        "outputId": "40011d02-6a64-444e-d6b2-b278c05536c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U -q \"google-genai>=1.16.0\"\n",
        "%pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "MODEL_ID=\"gemini-2.5-pro\" # @param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash-preview-05-20\", \"gemini-2.5-pro-preview-06-05\"] {\"allow-input\":true, isTemplate: true}\n",
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown\n",
        "# 文件读取\n",
        "from docx import Document\n",
        "import os\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. 从音频提取知识点，得到详细版笔记"
      ],
      "metadata": {
        "id": "V0mUjsKE_C2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from docx import Document\n",
        "\n",
        "# ========== 基本路径设置 ==========\n",
        "input_folder = r\"/content/input\"      # 你放原始 docx 文件的文件夹路径\n",
        "output_folder = r\"/content/results\"        # 输出 result.txt 的文件夹\n",
        "\n",
        "# 确保输出文件夹存在\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 遍历文件夹中的所有 docx 文件\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".docx\"):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # 从文件名中提取 P 后面的数字\n",
        "        match = re.search(r\"P(\\d+)\", filename)\n",
        "        if match:\n",
        "            num = int(match.group(1)) - 1  # 提取数字并减 1\n",
        "            name_part = f\"S{num}\"          # 生成 S16 这样的命名\n",
        "        else:\n",
        "            name_part = os.path.splitext(filename)[0]  # 如果没匹配到，就用原名\n",
        "\n",
        "        # 读取文档内容\n",
        "        doc = Document(file_path)\n",
        "        text_content = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "        # 构造 prompt\n",
        "        prompt = f\"\"\"\n",
        "        请将以下课程音频的转写文本进行整理与提炼，提取出每个单词的知识点，输出为结构化的 Markdown 文件。\n",
        "\n",
        "        格式要求如下：\n",
        "\n",
        "        单词（Word）\n",
        "        【释】[词性]. [含义1]；[词性]. [含义2]（如有多个含义，均列出；若为动词，请标明 vt. / vi.）\n",
        "        【例】\n",
        "        “[例句1]” ——（解释例句中该单词的含义）\n",
        "        “[例句2]” ——（展示固定搭配或常用短语）\n",
        "        【记】说明记忆方式（如词根词缀、联想、场景记忆等）\n",
        "        【衍】列出主要衍生词，并说明词性和含义\n",
        "        【同】列出常见同义词（如有细微语义区别，可补充简要辨析）\n",
        "        【反】列出常见反义词\n",
        "\n",
        "        每个单词之间请用三条连字符 --- 分隔，并在前后各保留一个空行。\n",
        "\n",
        "        处理规则：\n",
        "\n",
        "        仅根据音频内容提取知识点，不添加未提及信息；\n",
        "        若某项内容未出现，请直接省略该行；\n",
        "        所有输出必须格式对齐、整洁、无多余缩进；\n",
        "        输出为纯 Markdown 文本，便于导入 Notion / Obsidian。\n",
        "        {text_content}\n",
        "        \"\"\"\n",
        "        thinking_budget = 4096 # @param {type:\"slider\", min:0, max:24576, step:1}\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(\n",
        "                thinking_config=types.ThinkingConfig(\n",
        "                    thinking_budget=thinking_budget\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 保存结果\n",
        "        output_path = os.path.join(output_folder, f\"{name_part}_result.txt\")\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "        print(f\"已处理文件：{filename} → {output_path}\")\n",
        "\n",
        "print(\"\\n全部处理完成 ✅\")"
      ],
      "metadata": {
        "id": "41kKpKGb_-MJ",
        "outputId": "99f96d63-7057-425c-cd21-bc863e27fddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "已处理文件：P36_原文.docx → /content/results/S35_result.txt\n",
            "已处理文件：P38_原文.docx → /content/results/S37_result.txt\n",
            "已处理文件：P34_原文.docx → /content/results/S33_result.txt\n",
            "已处理文件：P46_原文.docx → /content/results/S45_result.txt\n",
            "已处理文件：P26_原文.docx → /content/results/S25_result.txt\n",
            "已处理文件：P47_原文.docx → /content/results/S46_result.txt\n",
            "已处理文件：P49_原文.docx → /content/results/S48_result.txt\n",
            "已处理文件：P33_原文.docx → /content/results/S32_result.txt\n",
            "已处理文件：P42_原文.docx → /content/results/S41_result.txt\n",
            "已处理文件：P27_原文.docx → /content/results/S26_result.txt\n",
            "已处理文件：P51_原文.docx → /content/results/S50_result.txt\n",
            "已处理文件：P25_原文.docx → /content/results/S24_result.txt\n",
            "已处理文件：P41_原文.docx → /content/results/S40_result.txt\n",
            "已处理文件：P40_原文.docx → /content/results/S39_result.txt\n",
            "已处理文件：P50_原文.docx → /content/results/S49_result.txt\n",
            "已处理文件：P48_原文.docx → /content/results/S47_result.txt\n",
            "已处理文件：P28_原文.docx → /content/results/S27_result.txt\n",
            "已处理文件：P29_原文.docx → /content/results/S28_result.txt\n",
            "已处理文件：P32_原文.docx → /content/results/S31_result.txt\n",
            "已处理文件：P37_原文.docx → /content/results/S36_result.txt\n",
            "已处理文件：P35_原文.docx → /content/results/S34_result.txt\n",
            "已处理文件：P39_原文.docx → /content/results/S38_result.txt\n",
            "已处理文件：P43_原文.docx → /content/results/S42_result.txt\n",
            "已处理文件：P44_原文.docx → /content/results/S43_result.txt\n",
            "\n",
            "全部处理完成 ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# 将文件夹打包为 zip 文件\n",
        "shutil.make_archive('results', 'zip', '/content/results')\n",
        "\n",
        "# 下载 zip 文件\n",
        "files.download('results.zip')\n"
      ],
      "metadata": {
        "id": "1nGa2bRjM-wg",
        "outputId": "49e528d7-d6cc-483f-fbba-fd76cb148c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2648868-29ae-4fa4-9ff3-5f530f956f01\", \"results.zip\", 61794)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "1f7da0a9-1418-4dd7-cdf6-612011e85a8f",
        "id": "3jT5kayXKnrb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PackageNotFoundError",
          "evalue": "Package not found at '/content/GRE单词地基词全集精讲 ｜ 北大学姐真人带背&串讲考点 ｜ 比GRE3000&佛脚词汇更高效 p07 S6-42个单词 - P07_原文.docx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3501921486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 加载 Word 文档\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/GRE单词地基词全集精讲 ｜ 北大学姐真人带背&串讲考点 ｜ 比GRE3000&佛脚词汇更高效 p07 S6-42个单词 - P07_原文.docx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 打开 txt 文件准备写入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/docx/api.py\u001b[0m in \u001b[0;36mDocument\u001b[0;34m(docx)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m     26\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdocument_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DocumentPart\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/docx/opc/package.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"\"\"Return an |OpcPackage| instance loaded with the contents of `pkg_file`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mpkg_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/docx/opc/pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(pkg_file)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"\"\"Return a |PackageReader| instance loaded with contents of `pkg_file`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mphys_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/docx/opc/phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, pkg_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mreader_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ZipPkgReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Package not found at '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume it's a stream and pass it to Zip reader to sort out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mreader_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ZipPkgReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: Package not found at '/content/GRE单词地基词全集精讲 ｜ 北大学姐真人带背&串讲考点 ｜ 比GRE3000&佛脚词汇更高效 p07 S6-42个单词 - P07_原文.docx'"
          ]
        }
      ],
      "source": [
        "# GRE版\n",
        "\n",
        "# 加载 Word 文档\n",
        "doc = Document('/content/GRE单词地基词全集精讲 ｜ 北大学姐真人带背&串讲考点 ｜ 比GRE3000&佛脚词汇更高效 p07 S6-42个单词 - P07_原文.docx')\n",
        "\n",
        "# 打开 txt 文件准备写入\n",
        "with open('output.txt', 'w', encoding='utf-8') as txt_file:\n",
        "    # 遍历文档中的所有段落\n",
        "    for para in doc.paragraphs:\n",
        "        txt_file.write(para.text + '\\n')  # 将每个段落写入 txt 文件并换行\n",
        "\n",
        "\n",
        "filename = r\"output.txt\"\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    text_content = f.read()\n",
        "\n",
        "# 构造 prompt\n",
        "prompt = f\"\"\"\n",
        "请将以下课程音频的转写文本进行整理与提炼，提取出每个单词的知识点，输出为结构化的 Markdown 文件。\n",
        "\n",
        "格式要求如下：\n",
        "\n",
        "单词（Word）\n",
        "【释】[词性]. [含义1]；[词性]. [含义2]（如有多个含义，均列出；若为动词，请标明 vt. / vi.）\n",
        "【例】\n",
        "“[例句1]” ——（解释例句中该单词的含义）\n",
        "“[例句2]” ——（展示固定搭配或常用短语）\n",
        "【记】说明记忆方式（如词根词缀、联想、场景记忆等）\n",
        "【衍】列出主要衍生词，并说明词性和含义\n",
        "【同】列出常见同义词（如有细微语义区别，可补充简要辨析）\n",
        "【反】列出常见反义词\n",
        "\n",
        "每个单词之间请用三条连字符 --- 分隔，并在前后各保留一个空行。\n",
        "\n",
        "处理规则：\n",
        "\n",
        "仅根据音频内容提取知识点，不添加未提及信息；\n",
        "\n",
        "若某项内容未出现，请直接省略该行；\n",
        "\n",
        "所有输出必须格式对齐、整洁、无多余缩进；\n",
        "\n",
        "输出为纯 Markdown 文本，便于导入 Notion / Obsidian。\n",
        "{text_content}\n",
        "\"\"\"\n",
        "thinking_budget = 4096 # @param {type:\"slider\", min:0, max:24576, step:1}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(\n",
        "            thinking_budget=thinking_budget\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# 将 response.text 保存为 result.txt 文件\n",
        "with open(\"result.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(\"保存完成：result.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3CAp9YrQYq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4b1e4d-3bbc-4625-bfe2-f2cd2d902438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "保存完成：result.txt\n"
          ]
        }
      ],
      "source": [
        "# TOFEL版\n",
        "\n",
        "# 加载 Word 文档\n",
        "doc = Document('/content/GRE单词地基词全集精讲 ｜ 北大学姐真人带背&串讲考点 ｜ 比GRE3000&佛脚词汇更高效 p01 S1-57个单词 - P01_原文.docx')\n",
        "\n",
        "# 打开 txt 文件准备写入\n",
        "with open('output.txt', 'w', encoding='utf-8') as txt_file:\n",
        "    # 遍历文档中的所有段落\n",
        "    for para in doc.paragraphs:\n",
        "        txt_file.write(para.text + '\\n')  # 将每个段落写入 txt 文件并换行\n",
        "\n",
        "\n",
        "filename = r\"output.txt\"\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    text_content = f.read()\n",
        "\n",
        "# 构造 prompt\n",
        "prompt = f\"\"\"\n",
        "请将以下的课程音频转写文件进行处理，提取知识点，整理成结构化的Markdown文件。格式要求如下：\n",
        "------\n",
        "\n",
        "# 单词（Word）\n",
        "\n",
        "- **meanings**：\n",
        "  - [词性]. [含义1]\n",
        "  - [词性]. [含义2]（如有多个意思，均列出）\n",
        "- **usage**：\n",
        "  - \"[例句1]\"（本单词在该例句中的含义）\n",
        "  - \"[例句2]\"（固定搭配或用法示例）\n",
        "     （每条分行，条理清晰）\n",
        "- **related words**：\n",
        "  - **SYN**（近义词）：\n",
        "    - [近义词1]（词性. 含义）\n",
        "      - [例句或补充说明]（如果用法超过两条，另起二级标题详细说明）\n",
        "    - [近义词2]（词性. 含义）\n",
        "      - [例句或补充说明]\n",
        "  - **ANTONYM**（反义词）：\n",
        "    - [反义词1]（词性. 含义）\n",
        "  - **DERIVATIVE WORDS**（衍生词）：\n",
        "    - [衍生词1]（词性. 含义）\n",
        "    - [衍生词2]（词性. 含义）\n",
        "      - [例句或补充说明]\n",
        "- **mnemonic**：\n",
        "  - 词根`[词根]` = [词根含义]，解释词义来源或联想\n",
        "  - 其他记忆方法或助记技巧\n",
        "- **notes**：\n",
        "  - [补充说明、用法注意或其他无法归类内容]\n",
        "\n",
        "------\n",
        "\n",
        "**补充说明：**\n",
        "\n",
        "- 若某一属性（meanings、usage、related words、mnemonic、notes）没有内容，则该属性可省略，不必空列。\n",
        "\n",
        "- 若related word中某词的usage超过两条，需在该词下另用二级标题写出，且保持相同结构（meanings、usage、related words、mnemonic、notes）。\n",
        "- 所有用例、短语等均需分行列出，确保阅读方便。\n",
        "- 若某知识点不能归入 meanings、usage、related words、mnemonic 四类，则归入 notes。\n",
        "\n",
        "{text_content}\n",
        "\"\"\"\n",
        "thinking_budget = 4096 # @param {type:\"slider\", min:0, max:24576, step:1}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(\n",
        "            thinking_budget=thinking_budget\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# 将 response.text 保存为 result.txt 文件\n",
        "with open(\"result.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(\"保存完成：result.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.详细版笔记精炼化\n",
        "### 2.1 传入当天单词总表，分批次输入"
      ],
      "metadata": {
        "id": "PPCeIb5w5hGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import shutil\n",
        "def split_md_by_sr(filename, output_dir,split_pattern=r'(SR\\d+)'):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # 匹配 SR后面跟数字，捕获分割点\n",
        "    pattern = re.compile(split_pattern)\n",
        "    parts = pattern.split(content)\n",
        "    for i, part in enumerate(parts):\n",
        "      print(f\"parts[{i}]: {repr(part)}\")\n",
        "\n",
        "    # parts格式： ['', 'SR1', 内容1, 'SR2', 内容2, ...]\n",
        "    for i in range(1, len(parts), 2):\n",
        "        title = parts[i].strip()  # SR编号\n",
        "        body = parts[i+1].strip() if (i+1) < len(parts) else ''\n",
        "\n",
        "        # 生成文件名，比如 SR1.txt\n",
        "        out_path = os.path.join(output_dir, f\"{title}.txt\")\n",
        "\n",
        "        with open(out_path, 'w', encoding='utf-8') as fout:\n",
        "            # 保留编号作为第一行\n",
        "            fout.write(f\"{title}\\n{body}\")\n",
        "\n",
        "    print(f\"拆分完成，文件保存在：{output_dir}\")\n",
        "\n",
        "input_file = r\"/content/SR11.txt\"\n",
        "output_folder = r\"/content/files\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    print(f\"文件夹已创建：{output_folder}\")\n",
        "else:\n",
        "    print(f\"文件夹已存在：{output_folder}\")\n",
        "\n",
        "# 删除文件夹里所有内容（文件和子文件夹）\n",
        "for filename in os.listdir(output_folder):\n",
        "    file_path = os.path.join(output_folder, filename)\n",
        "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "        os.unlink(file_path)  # 删除文件或符号链接\n",
        "    elif os.path.isdir(file_path):\n",
        "        shutil.rmtree(file_path)  # 递归删除文件夹及里面所有内容\n",
        "split_md_by_sr(input_file, output_folder, split_pattern=r'（SR\\d+）')"
      ],
      "metadata": {
        "id": "5ItulFKa52dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 汇总得到简化版笔记"
      ],
      "metadata": {
        "id": "V-hETH_g5viR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "input_dir = \"/content/files\"\n",
        "output_file = \"/content/result.txt\"\n",
        "\n",
        "# 先清空result.md（如果已存在）\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"\")\n",
        "# 重新排序\n",
        "def extract_number(filename):\n",
        "    # 用正则匹配文件名中的数字部分\n",
        "    match = re.search(r'(\\d+)', filename)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    else:\n",
        "        # 如果没有数字，返回一个大数，保证排序靠后\n",
        "        return float('inf')\n",
        "files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
        "files_sorted = sorted(files, key=extract_number)\n",
        "\n",
        "thinking_budget = 4096 # @param {type:\"slider\", min:0, max:24576, step:1}\n",
        "for filename in files_sorted:\n",
        "    if not filename.endswith(\".txt\"):\n",
        "        continue\n",
        "    input_path = os.path.join(input_dir, filename)\n",
        "\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        text_content = f.read()\n",
        "    prompt = f\"\"\"\n",
        "    请你提取以下内容，并用 Markdown 格式输出：\n",
        "\n",
        "    核心单词（用三级标题 ### 单词 标明）\n",
        "    本单词的固定搭配\n",
        "\n",
        "    本单词的用法\n",
        "\n",
        "    本单词的例句\n",
        "\n",
        "    衍生词\n",
        "\n",
        "    衍生词的用法和例句\n",
        "\n",
        "    要求：\n",
        "\n",
        "    核心单词用三级标题标明，如 ### abide，每个单词只出现一次，位于该单词所有表达之前；\n",
        "\n",
        "    其他表达以有序列表形式呈现，格式如下：\n",
        "\n",
        "    markdown\n",
        "    复制\n",
        "    编辑\n",
        "    1. \"英文表达\" (知识点单词 本句中涉及的意思或用法 中文翻译)\n",
        "        * 例句（**加粗中文翻译，方便回想**）\n",
        "    只提取英文表达，\n",
        "\n",
        "    “知识点单词”、“本句中涉及的意思或用法”、“中文翻译”由你基于原文内容准确理解并用简洁中文表达，避免逐字照搬；\n",
        "\n",
        "    例句紧跟在对应表达下面，用缩进的 * 标记单独一行展示，保持例句的英文原文和标点不变；\n",
        "\n",
        "    删除所有笔记中的注释、解释、翻译等无关内容，只保留上述表达和例句；\n",
        "\n",
        "    同一表达有多条例句时，每条例句均单独列出；\n",
        "\n",
        "    输出顺序严格为：核心单词标题 → 固定搭配 → 用法 → 例句 → 衍生词 → 衍生词用法及例句；\n",
        "\n",
        "    确保中文释义精准简洁，便于记忆与回想。\n",
        "\n",
        "    示例输入（示范）：\n",
        "    pgsql\n",
        "    复制\n",
        "    编辑\n",
        "    # abound\n",
        "\n",
        "    - Meaning: Exist in large numbers\n",
        "      - Used as an intransitive verb to indicate abundance.\n",
        "      - Example: \"Stories about his travels abound\" (关于他的游历的故事有很多).\n",
        "    - Phrase: abound with\n",
        "      - Means to be full of or rich in something.\n",
        "      - Example: \"The lake abounds with fish\" (这个湖有很多鱼).\n",
        "    示例输出：\n",
        "    markdown\n",
        "    复制\n",
        "    编辑\n",
        "    ### abound\n",
        "    1. \"abound\" (动词 表示数量多)\n",
        "        * Stories about his travels abound (关于他的游历的故事有很多).\n",
        "    2. \"abound with\" (固定搭配 充满)\n",
        "        * The lake abounds with fish (这个湖有很多鱼).\n",
        "\n",
        "    {text_content}\n",
        "    \"\"\"\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=types.GenerateContentConfig(\n",
        "            thinking_config=types.ThinkingConfig(\n",
        "                thinking_budget=thinking_budget\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "  # 追加写入统一result.md文件，且用一级标题分割\n",
        "    with open(output_file, 'a', encoding='utf-8') as fout:\n",
        "        # 以文件名（去除扩展名）作为一级标题\n",
        "        section_title = os.path.splitext(filename)[0]\n",
        "        fout.write(f\"# {section_title}\\n\\n\")\n",
        "        fout.write(response.text)\n",
        "        fout.write(\"\\n\\n\")\n",
        "    print(f\"{filename} 处理完成，结果追加写入 {output_file}\")\n",
        "\n",
        "print(\"保存完成：result.md\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q07XPppopqRO",
        "outputId": "baaf9d7f-2d99-434b-b620-b9dc079c7582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SR11.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR12.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR13.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR14.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR15.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR17.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR18.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR19.txt 处理完成，结果追加写入 /content/result.md\n",
            "SR20.txt 处理完成，结果追加写入 /content/result.md\n",
            "保存完成：result.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文件读取\n",
        "filename = r\"/content/Art艺术.txt\"\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    text_content = f.read()\n",
        "\n",
        "# 构造 prompt\n",
        "prompt = f\"\"\"\n",
        "任务目标\n",
        "将原始英文单词列表（包含可能的音标、词性、中文释义）转换成标准 Markdown 单词表，每个词条一行，列出英文单词 / 音标 / 中文释义三部分，同时保留章节标题或类别标记。\n",
        "处理规则\n",
        "1. 词条结构\n",
        "    格式：` 单词  音标  中文释义 `\n",
        "2. 单词识别\n",
        "    单词通常位于音标之前，去除多余空格与换行。\n",
        "    复合词或短语保持原格式（如 still life）。\n",
        "    OCR 错误明显时尝试修正（如 countrvside → countryside）。\n",
        "3. 音标提取\n",
        "    识别方括号 `[]` 或斜杠 `/` 中的内容作为音标。\n",
        "    去掉混入的词性标记（如 `n`, `adj`）和多余空格。\n",
        "    若音标缺失，请给出。\n",
        "4. 中文释义\n",
        "    音标之后的中文内容作为释义。\n",
        "    保留多义项（用 `；` 分隔），删除多余空格和标点。\n",
        "    OCR 明显错误修正（如 `泊画`→`油画`，`真止的`→`真正的`，`观煮视角`→`观察视角`）。\n",
        "5. 特殊处理\n",
        "    同义词（`=`）或替代表达（`/`）分成多条独立词条。\n",
        "    删除非单词的乱码、重复标记。\n",
        "    保留章节标题和类别标记，可用 单独的一行：` Art艺术   ` 形式表示（音标和释义可留空）。\n",
        "6. 输出要求\n",
        "    按原文顺序输出词条，不做字母排序。\n",
        "    章节标题和类别标记应作为独立行保留。\n",
        "-\n",
        "{text_content}\n",
        "\"\"\"\n",
        "thinking_budget = 4096 # @param {type:\"slider\", min:0, max:24576, step:1}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(\n",
        "            thinking_budget=thinking_budget\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "# 将 response.text 保存为 result.txt 文件\n",
        "with open(\"result.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(\"保存完成：result.txt\")"
      ],
      "metadata": {
        "id": "uc1apo7AqHNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32977c42-100e-4613-e8d7-10330b3868f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "保存完成：result.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Get_started_thinking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}